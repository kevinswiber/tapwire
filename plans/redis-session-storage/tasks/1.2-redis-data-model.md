# Task 1.2: Design Redis Data Model

## Objective
Design an efficient Redis data model for storing MCP sessions, frames, and metadata that optimizes for the access patterns observed in SessionManager.

## Analysis Required

### 1. Access Pattern Analysis
Review SessionManager to identify:
- Most frequent operations (get_session, update_activity)
- Bulk operations (list_sessions, cleanup)
- Atomic requirements (request tracking)
- Performance-critical paths

### 2. Data Size Estimation
Calculate storage requirements:
- Average session size: ~1KB metadata
- Average frame size: 1-10KB
- Frames per session: 10-1000
- Concurrent sessions: 100-10,000

## Deliverables

### 1. Redis Schema Document
Location: `plans/redis-session-storage/analysis/redis-schema.md`

Document should include:
- Key naming conventions
- Data type for each key pattern
- TTL strategies
- Index structures
- Atomic operation requirements

### 2. Data Structure Definitions

#### Session Storage
```redis
# Session metadata (Hash)
Key: shadowcat:session:{session_id}
Type: Hash
Fields:
  id              -> string (session UUID)
  transport_type  -> string ("stdio"|"http"|"sse")
  status          -> string ("active"|"completed"|"failed"|"timeout")
  state           -> string (session state machine state)
  created_at      -> integer (unix timestamp ms)
  last_activity   -> integer (unix timestamp ms)
  frame_count     -> integer
  client_info     -> string (JSON, optional)
  server_info     -> string (JSON, optional)
  version_state   -> string (JSON)
  tags            -> string (JSON array)

TTL: 24 hours (configurable)
```

#### Frame Storage
```redis
# Option A: List of serialized frames
Key: shadowcat:frames:{session_id}
Type: List
Values: Serialized MessageEnvelope (bincode)

# Option B: Stream (for append-only log)
Key: shadowcat:frames:{session_id}
Type: Stream
Fields: id, direction, timestamp, message

# Option C: Sorted Set with timestamp scores
Key: shadowcat:frames:{session_id}
Type: Sorted Set
Score: timestamp
Member: serialized frame
```

#### Indices and Sets
```redis
# Active sessions
shadowcat:sessions:active -> Set of session_ids

# Sessions by status
shadowcat:sessions:status:{status} -> Set of session_ids

# Session expiry tracking
shadowcat:sessions:expiry -> Sorted Set (score: expiry_time, member: session_id)

# LRU tracking
shadowcat:sessions:lru -> Sorted Set (score: last_access, member: session_id)

# Pending requests
shadowcat:requests:{session_id} -> Hash (field: request_id, value: JSON)
```

#### Metrics
```redis
# Counters
shadowcat:metrics:sessions:created -> String (integer counter)
shadowcat:metrics:sessions:completed -> String (integer counter)
shadowcat:metrics:frames:total -> String (integer counter)

# Gauges
shadowcat:metrics:sessions:active -> String (current count)
shadowcat:metrics:pool:connections -> String (current count)
```

### 3. Lua Scripts for Atomicity

#### Create Session Atomically
```lua
-- create_session.lua
local session_key = KEYS[1]
local active_set = KEYS[2]
local expiry_zset = KEYS[3]
local metrics_created = KEYS[4]
local metrics_active = KEYS[5]

local session_data = cjson.decode(ARGV[1])
local expiry_time = ARGV[2]

-- Create session hash
for field, value in pairs(session_data) do
    redis.call('HSET', session_key, field, value)
end

-- Add to indices
redis.call('SADD', active_set, session_data.id)
redis.call('ZADD', expiry_zset, expiry_time, session_data.id)

-- Update metrics
redis.call('INCR', metrics_created)
redis.call('INCR', metrics_active)

return 1
```

#### Complete Request Atomically
```lua
-- complete_request.lua
local requests_key = KEYS[1]
local request_id = ARGV[1]

local request_data = redis.call('HGET', requests_key, request_id)
if request_data then
    redis.call('HDEL', requests_key, request_id)
    return request_data
end
return nil
```

### 4. Performance Optimization Plan

#### Pipelining Strategy
```rust
// Example: Update session activity efficiently
pipeline()
    .hset("session:{id}", "last_activity", now)
    .zadd("sessions:lru", now, session_id)
    .expire("session:{id}", ttl)
    .exec()
```

#### Batch Operations
```rust
// Example: Get multiple sessions
pipeline()
    .hgetall("session:{id1}")
    .hgetall("session:{id2}")
    .hgetall("session:{id3}")
    .exec()
```

## Comparison of Storage Options

### Frames Storage Comparison

| Option | Pros | Cons | Use Case |
|--------|------|------|----------|
| List | Simple, ordered, fast append | No timestamp index | Sequential replay |
| Stream | Built-in timestamps, consumer groups | More complex API | Event sourcing |
| Sorted Set | Time-range queries, deduplication | Higher memory | Time-based queries |

**Recommendation**: Start with List for simplicity, migrate to Stream if needed

### Serialization Format Comparison

| Format | Size | Speed | Human Readable | Schema Evolution |
|--------|------|-------|----------------|------------------|
| JSON | Large | Slow | Yes | Easy |
| Bincode | Small | Fast | No | Hard |
| MessagePack | Small | Fast | No | Medium |
| Protobuf | Small | Fast | No | Easy |

**Recommendation**: MessagePack for balance of size, speed, and flexibility

## Implementation Considerations

### 1. Key Expiration Strategy
- Set TTL on session keys (24 hours default)
- Use expiry sorted set for batch cleanup
- Implement lazy deletion for expired sessions

### 2. Memory Optimization
- Use Redis memory optimization settings
- Implement frame pagination (don't load all at once)
- Consider compression for large frames

### 3. Consistency Guarantees
- Use transactions for multi-key operations
- Implement optimistic locking with WATCH
- Design for eventual consistency where acceptable

## Testing Requirements

- [ ] Benchmark different frame storage options
- [ ] Test Lua script atomicity
- [ ] Measure memory usage per session
- [ ] Validate TTL and cleanup behavior
- [ ] Test index consistency under load

## Success Criteria

- ✅ Complete schema documented
- ✅ All access patterns supported efficiently
- ✅ Atomic operations identified and scripted
- ✅ Memory usage projections calculated
- ✅ Performance targets validated

## Notes

- Consider Redis Cluster sharding strategy (by session_id)
- Plan for Redis 7.0 features (functions, triggers)
- Document migration path from in-memory to Redis
- Consider backup and recovery strategies

## Estimated Duration
2 hours

## Dependencies
- Task 1.1 (SessionStore trait definition)